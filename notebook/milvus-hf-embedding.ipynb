{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45529677-944d-474a-b340-fbfdccfdba6e",
   "metadata": {},
   "source": [
    "Tutorial: https://milvus.io/docs/integrate_with_hugging-face.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c793b-dcaa-4f73-bf64-2aee2010ee7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pymilvus transformers datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fbf12b-b327-46b6-b871-9ec16cf58738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a4747a-e18f-4491-81ff-fa41fd0d49fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 7.62k/7.62k [00:00<00:00, 20.7MB/s]\n",
      "Downloading data: 100%|██████████| 14.5M/14.5M [00:00<00:00, 20.5MB/s]\n",
      "Downloading data: 100%|██████████| 1.82M/1.82M [00:00<00:00, 4.37MB/s]\n",
      "Generating train split: 100%|██████████| 87599/87599 [00:00<00:00, 297151.02 examples/s]\n",
      "Generating validation split: 100%|██████████| 10570/10570 [00:00<00:00, 288400.52 examples/s]\n",
      "Map: 100%|██████████| 11/11 [00:00<00:00, 1291.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'question', 'answer'],\n",
      "    num_rows: 11\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "DATASET = \"squad\"  # Name of dataset from HuggingFace Datasets\n",
    "INSERT_RATIO = 0.001  # Ratio of example dataset to be inserted\n",
    "\n",
    "data = load_dataset(DATASET, split=\"validation\")\n",
    "data = data.train_test_split(test_size=INSERT_RATIO, seed=42)[\"test\"]\n",
    "data = data.map(\n",
    "    lambda val: {\"answer\": val[\"answers\"][\"text\"][0]},\n",
    "    remove_columns=[\"id\", \"answers\", \"context\"],\n",
    ")\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d46f52c-382f-40aa-ac6f-f53514ba75e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11/11 [00:00<00:00, 13.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "MODEL = (\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"  # Name of model from HuggingFace Models\n",
    ")\n",
    "INFERENCE_BATCH_SIZE = 64  # Batch size of model inference\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModel.from_pretrained(MODEL)\n",
    "\n",
    "\n",
    "def encode_text(batch):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(\n",
    "        batch[\"question\"], padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    token_embeddings = model_output[0]\n",
    "    attention_mask = encoded_input[\"attention_mask\"]\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    sentence_embeddings = torch.sum(\n",
    "        token_embeddings * input_mask_expanded, 1\n",
    "    ) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    batch[\"question_embedding\"] = torch.nn.functional.normalize(\n",
    "        sentence_embeddings, p=2, dim=1\n",
    "    )\n",
    "    return batch\n",
    "\n",
    "\n",
    "data = data.map(encode_text, batched=True, batch_size=INFERENCE_BATCH_SIZE)\n",
    "data_list = data.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b7b241-9c88-411f-92d6-d3d8bc9c18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "\n",
    "MILVUS_URI = \"http://milvus.milvus.svc.cluster.local\"  # Connection URI\n",
    "COLLECTION_NAME = \"huggingface_test\"  # Collection name\n",
    "DIMENSION = 384  # Embedding dimension depending on model\n",
    "\n",
    "milvus_client = MilvusClient(MILVUS_URI)\n",
    "if milvus_client.has_collection(collection_name=COLLECTION_NAME):\n",
    "    milvus_client.drop_collection(collection_name=COLLECTION_NAME)\n",
    "milvus_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    dimension=DIMENSION,\n",
    "    auto_id=True,  # Enable auto id\n",
    "    enable_dynamic_field=True,  # Enable dynamic fields\n",
    "    vector_field_name=\"question_embedding\",  # Map vector field name and embedding column in dataset\n",
    "    consistency_level=\"Strong\",  # To enable search with latest data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64fda26f-3c01-4c03-8b21-57bcf2f1654d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insert_count': 11,\n",
       " 'ids': [451627567490287437, 451627567490287438, 451627567490287439, 451627567490287440, 451627567490287441, 451627567490287442, 451627567490287443, 451627567490287444, 451627567490287445, 451627567490287446, 451627567490287447],\n",
       " 'cost': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milvus_client.insert(collection_name=COLLECTION_NAME, data=data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67ccabc-743e-48c8-92ac-b42ea171937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is LGM?\n",
      "{'answer': 'Last Glacial Maximum', 'score': 0.956273078918457, 'original question': 'What does LGM stands for?'}\n",
      "{'answer': 'coordinate the response to the embargo', 'score': 0.21201416850090027, 'original question': 'Why was this short termed organization created?'}\n",
      "{'answer': '\"Reducibility Among Combinatorial Problems\"', 'score': 0.1945795714855194, 'original question': 'What is the paper written by Richard Karp in 1972 that ushered in a new era of understanding between intractability and NP-complete problems?'}\n",
      "\n",
      "\n",
      "Question: When did Massachusetts first mandate that children be educated in schools?\n",
      "{'answer': '1852', 'score': 0.9709996581077576, 'original question': 'In what year did Massachusetts first require children to be educated in schools?'}\n",
      "{'answer': 'several regional colleges and universities', 'score': 0.341647207736969, 'original question': 'In 1890, who did the university decide to team up with?'}\n",
      "{'answer': '1962', 'score': 0.19310054183006287, 'original question': 'When were stromules discovered?'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = {\n",
    "    \"question\": [\n",
    "        \"What is LGM?\",\n",
    "        \"When did Massachusetts first mandate that children be educated in schools?\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "question_embeddings = [v.tolist() for v in encode_text(questions)[\"question_embedding\"]]\n",
    "\n",
    "search_results = milvus_client.search(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    data=question_embeddings,\n",
    "    limit=3,  # How many search results to output\n",
    "    output_fields=[\"answer\", \"question\"],  # Include these fields in search results\n",
    ")\n",
    "\n",
    "for q, res in zip(questions[\"question\"], search_results):\n",
    "    print(\"Question:\", q)\n",
    "    for r in res:\n",
    "        print(\n",
    "            {\n",
    "                \"answer\": r[\"entity\"][\"answer\"],\n",
    "                \"score\": r[\"distance\"],\n",
    "                \"original question\": r[\"entity\"][\"question\"],\n",
    "            }\n",
    "        )\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe418cf-bc5b-4552-9aea-f65adf8f2103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
